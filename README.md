# ğŸŒ©ï¸ Classification des Nuages avec le Deep Learning

Ce projet vise Ã  dÃ©velopper un systÃ¨me automatique de classification des nuages Ã  partir dâ€™images capturÃ©es depuis le sol, en utilisant des techniques avancÃ©es de deep learning telles que les CNN (MobileNetV2) et les Vision Transformers (ViT).

## ğŸ¯ Objectif du projet

Concevoir un outil capable de :

- ReconnaÃ®tre automatiquement les genres et motifs de nuages Ã  partir dâ€™images.
- Optimiser les prÃ©visions mÃ©tÃ©orologiques et lâ€™analyse du climat local.
- Exploiter des architectures rÃ©centes de deep learning malgrÃ© un corpus limitÃ©.

## ğŸ—‚ï¸ Structure du projet

- `data/` : contient les jeux de donnÃ©es CCSN et SWIMCAT.
- `models/` : implÃ©mentations de MobileNetV2 et Vision Transformer.
- `notebooks/` : notebooks Jupyter pour l'entraÃ®nement, la validation, l'Ã©valuation.
- `results/` : courbes dâ€™apprentissage, matrices de confusion, scores.
- `utils/` : fonctions de prÃ©traitement, dâ€™augmentation et de visualisation.

## ğŸ§  MÃ©thodologies

- **CNN (MobileNetV2)** : utilisÃ© avec et sans augmentation de donnÃ©es.
- **Vision Transformer (ViT-B/16)** : avec Shifted Patch Tokenization et Locality Self-Attention.
- **Triplet Loss** : pour simuler davantage de combinaisons dans des corpus rÃ©duits.

## ğŸ“Š Jeux de donnÃ©es utilisÃ©s

### 1. CCSN (Cirrus, Cumulus, Stratus, Nimbus)

- 2543 images 256Ã—256
- 11 classes originales, rÃ©duites Ã  9 pour Ã©viter les dÃ©sÃ©quilibres extrÃªmes.

### 2. SWIMCAT

- 784 images 125Ã—125
- 5 classes : Clear Sky, Patterned Clouds, Thick Dark Clouds, Thick White Clouds, Veil Clouds.

## âš™ï¸ EntraÃ®nement

| ModÃ¨le             | Accuracy (CCSN) | F1 (CCSN) | Accuracy (SWIMCAT) | F1 (SWIMCAT) |
| ------------------ | --------------- | --------- | ------------------ | ------------ |
| MobileNetV2 + Aug. | 78.4%           | 0.77      | 92.6%              | 0.91         |
| ViT                | 70.1%           | 0.68      | 88.3%              | 0.87         |

- Optimiseur : SGD ou AdamW
- Batch size : 8/16
- Early stopping avec patience = 20
- Techniques : horizontal flip, zoom, variation de luminositÃ©

## ğŸ” Analyse critique

- Les CNN sont plus robustes avec peu de donnÃ©es.
- ViT nÃ©cessite des corpus plus vastes malgrÃ© des ajustements locaux.
- Lâ€™augmentation amÃ©liore surtout la classification fine (CCSN).

## ğŸ”® Perspectives

- IntÃ©grer lâ€™auto-supervision pour rÃ©duire lâ€™effort dâ€™annotation.
- Collecter plus de donnÃ©es via des applications mobiles.
- Combiner CNN + ViT pour une meilleure robustesse.
- DÃ©ploiement sur des stations mÃ©tÃ©o basse consommation.
